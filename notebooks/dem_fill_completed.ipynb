{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almost the same as in the train.py script. Used to test new approaches and hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "sys.path.append('..')\n",
    "from scripts.inpaint_ops import d_wasserstein_loss, g_wasserstein_loss, min_max_tf_scaler2, mask_2_crop\n",
    "from scripts.data_processing_utils import DataLoader\n",
    "from models.networks.generator import dem_fill_net\n",
    "from models.networks.global_critic import build_wgan_discriminator_global\n",
    "from models.networks.local_critic import build_wgan_discriminator_local\n",
    "from models.inpaintModel import WGAN_GP, GANMonitor\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "DataLoader = DataLoader()\n",
    "\n",
    "# define version of Dataset:\n",
    "version = 'V1.7'\n",
    "\n",
    "\n",
    "dem = f'/home/robin/Nextcloud_sn/Masterarbeit/DataSet/{version}/DEMs'\n",
    "inner_outer = f'/home/robin/Nextcloud_sn/Masterarbeit/DataSet/{version}/Inner-Outer Mask'\n",
    "intersection = f'/home/robin/Nextcloud_sn/Masterarbeit/DataSet/{version}/Intersection Mask'\n",
    "intersection_small = f'/home/robin/Nextcloud_sn/Masterarbeit/DataSet/{version}/Intersection Mask Small'\n",
    "\n",
    "\n",
    "\n",
    "# define lists\n",
    "dem_list = DataLoader.populate_list(dem)\n",
    "inner_outer_list = DataLoader.populate_list(inner_outer)\n",
    "intersection_list = DataLoader.populate_list(intersection)\n",
    "intersection_small_list = DataLoader.populate_list(intersection_small)\n",
    "\n",
    "# shuffle the lists\n",
    "dem_list, inner_outer_list, intersection_list, intersection_small_list = DataLoader.shuffle_lists([dem_list, inner_outer_list, intersection_list,\n",
    "                                                                                                   intersection_small_list])\n",
    "\n",
    "batch_size = 16\n",
    "large_dim = 256\n",
    "small_dim = 64\n",
    "\n",
    "dem_tensor = tf.data.Dataset.from_generator(\n",
    "    DataLoader.load_dem_cv2,\n",
    "    args=[dem_list],\n",
    "    output_signature = tf.TensorSpec(shape = (large_dim,large_dim,1), dtype = tf.float32)\n",
    ").batch(batch_size)\n",
    "\n",
    "train_inner_outer = tf.data.Dataset.from_generator(\n",
    "    DataLoader.load_mask,\n",
    "    args=[inner_outer_list],\n",
    "    output_signature = tf.TensorSpec(shape = (large_dim,large_dim,1), dtype = tf.float32)\n",
    ").batch(batch_size)\n",
    "\n",
    "train_intersection = tf.data.Dataset.from_generator(\n",
    "    DataLoader.load_mask,\n",
    "    args=[intersection_list],\n",
    "    output_signature = tf.TensorSpec(shape = (large_dim,large_dim,1), dtype = tf.float32)\n",
    ").batch(batch_size)\n",
    "\n",
    "train_intersection_small = tf.data.Dataset.from_generator(\n",
    "    DataLoader.load_mask,\n",
    "    args=[intersection_small_list, (small_dim,small_dim)],\n",
    "    output_signature = tf.TensorSpec(shape = (small_dim,small_dim,1), dtype = tf.float32)\n",
    ").batch(batch_size)\n",
    "\n",
    "# normalize the DEMs\n",
    "\n",
    "train_norm_dems = dem_tensor.map(min_max_tf_scaler2, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# define the models\n",
    "generator = dem_fill_net(image_size=large_dim)\n",
    "global_discriminator = build_wgan_discriminator_global(image_size=large_dim)\n",
    "local_discriminator = build_wgan_discriminator_local(image_size=small_dim)\n",
    "\n",
    "wgan = WGAN_GP(generator = generator, global_critic = global_discriminator, local_critic = local_discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the prefetch buffer size\n",
    "train_dem = train_norm_dems.cache().prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "train_inner_outer = train_inner_outer.cache().prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "train_intersection = train_intersection.cache().prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "train_intersection_small = train_intersection_small.cache().prefetch(buffer_size = tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the datasets\n",
    "dataset = tf.data.Dataset.zip((train_dem, train_inner_outer, train_intersection,\n",
    "                               train_intersection_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callbacks:\n",
    "log_dir = '/home/robin/Nextcloud_sn/Masterarbeit/Results/logs'\n",
    "\n",
    "\n",
    "gan_monitor = GANMonitor(log_dir = log_dir,\n",
    "                        save_gen_path = '/home/robin/Nextcloud_sn/Masterarbeit/Results/networks/generator',\n",
    "                        data = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "LR = 0.0001\n",
    "LR_shedule = ExponentialDecay(initial_learning_rate = LR, decay_steps = 100000, decay_rate = 0.96, staircase = True)\n",
    "\n",
    "# define the optimizers\n",
    "d_optimzer_local = keras.optimizers.Adam(learning_rate = LR_shedule, beta_1 = 0.5, beta_2 = 0.999)\n",
    "d_optimizer_global = keras.optimizers.Adam(learning_rate = LR_shedule, beta_1 = 0.5, beta_2 = 0.999)\n",
    "g_optimizer = keras.optimizers.Adam(learning_rate = LR_shedule, beta_1 = 0.5, beta_2 = 0.999)\n",
    "\n",
    "# define the loss functions\n",
    "d_loss_fn = d_wasserstein_loss\n",
    "g_loss_fn = g_wasserstein_loss\n",
    "\n",
    "# compile the models\n",
    "wgan.compile(d_optimizer_local = d_optimzer_local, d_optimizer_global = d_optimizer_global, g_optimizer = g_optimizer,\n",
    "                d_loss_fn = d_loss_fn, g_loss_fn = g_loss_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.fit(dataset, epochs = NUM_EPOCHS, callbacks = [gan_monitor])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
